Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.81 GB / 15.93 GB (30.2%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'RNNModel': {'dropout': 0.1,
                                  'epochs': 20,
                                  'hidden_size': 64,
                                  'learning_rate': 0.001,
                                  'module': 'LSTM',
                                  'num_layers': 2,
                                  'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-25 08:50:18
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM/modelo"
Beginning AutoGluon training... Time limit = 3600s
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.77 GB / 15.93 GB (23.7%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.77 GB / 15.93 GB (23.7%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-04-25 08:55:49

Starting training. Start time is 2025-04-25 08:55:49
Models that will be trained: ['DeepAR']
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	-0.0364       = Validation score (-WQL)
	-0.0364       = Validation score (-WQL)
	59.89   s     = Training runtime
	59.89   s     = Training runtime
	0.12    s     = Validation (prediction) runtime
	0.12    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Training complete. Models trained: ['DeepAR']
Total runtime: 60.09 s
Total runtime: 60.09 s
Best model: DeepAR
Best model: DeepAR
Best model score: -0.0364
Best model score: -0.0364
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM/modelo"
Beginning AutoGluon training... Time limit = 3600s
Beginning AutoGluon training... Time limit = 3600s
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.29 GB / 15.93 GB (20.7%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.29 GB / 15.93 GB (20.7%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.29 GB / 15.93 GB (20.7%)
Disk Space Avail:   699.60 GB / 931.46 GB (75.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================

Starting training. Start time is 2025-04-25 08:58:28

Starting training. Start time is 2025-04-25 08:58:28

Starting training. Start time is 2025-04-25 08:58:28
Models that will be trained: ['DeepAR']
Models that will be trained: ['DeepAR']
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 3599.95s -> 3239.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 3599.95s -> 3239.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 3599.95s -> 3239.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0364       = Validation score (-WQL)
	-0.0364       = Validation score (-WQL)
	-0.0364       = Validation score (-WQL)
	34.62   s     = Training runtime
	34.62   s     = Training runtime
	34.62   s     = Training runtime
	0.14    s     = Validation (prediction) runtime
	0.14    s     = Validation (prediction) runtime
	0.14    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Not fitting ensemble as only 1 model was trained.
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Training complete. Models trained: ['DeepAR']
Training complete. Models trained: ['DeepAR']
Total runtime: 34.83 s
Total runtime: 34.83 s
Total runtime: 34.83 s
Best model: DeepAR
Best model: DeepAR
Best model: DeepAR
Best model score: -0.0364
Best model score: -0.0364
Best model score: -0.0364
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.75 GB / 7.88 GB (9.5%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-26 16:49:44
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3591.0s of the 3591.0s of remaining time.
	-0.0408       = Validation score (-WQL)
	152.40  s     = Training runtime
	0.28    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Total runtime: 152.90 s
Best model: DeepAR
Best model score: -0.0408
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM/modelo"
Beginning AutoGluon training... Time limit = 3600s
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.74 GB / 7.88 GB (9.4%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.74 GB / 7.88 GB (9.4%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 48,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-04-26 16:58:50

Starting training. Start time is 2025-04-26 16:58:50
Models that will be trained: ['DeepAR']
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3599.9s of the 3599.9s of remaining time.
Training timeseries model DeepAR. Training for up to 3599.9s of the 3599.9s of remaining time.
	Time limit adjusted due to model hyperparameters: 3599.77s -> 3239.79s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 3599.77s -> 3239.79s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0408       = Validation score (-WQL)
	-0.0408       = Validation score (-WQL)
	50.07   s     = Training runtime
	50.07   s     = Training runtime
	0.23    s     = Validation (prediction) runtime
	0.23    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Training complete. Models trained: ['DeepAR']
Total runtime: 50.47 s
Total runtime: 50.47 s
Best model: DeepAR
Best model: DeepAR
Best model score: -0.0408
Best model score: -0.0408
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Model not specified in predict, will default to the model with the best validation score: DeepAR
Beginning AutoGluon training... Time limit = 3600s
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.55 GB / 7.88 GB (7.0%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.55 GB / 7.88 GB (7.0%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-04-26 17:25:41

Starting training. Start time is 2025-04-26 17:25:41
Models that will be trained: ['WaveNet']
Models that will be trained: ['WaveNet']
Training timeseries model WaveNet. Training for up to 3599.6s of the 3599.6s of remaining time.
Training timeseries model WaveNet. Training for up to 3599.6s of the 3599.6s of remaining time.
	Time limit adjusted due to model hyperparameters: 3599.51s -> 3239.56s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 3599.51s -> 3239.56s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused WaveNet to fail during training... Skipping this model.
	Warning: Exception caused WaveNet to fail during training... Skipping this model.
	name 'exit' is not defined
	name 'exit' is not defined
Training complete. Models trained: []
Training complete. Models trained: []
Total runtime: 133.61 s
Total runtime: 133.61 s
Trainer has no fit models that can predict.
Trainer has no fit models that can predict.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.13 GB / 7.88 GB (14.4%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.13 GB / 7.88 GB (14.4%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-04-26 17:27:58

Starting training. Start time is 2025-04-26 17:27:58
Models that will be trained: ['WaveNet']
Models that will be trained: ['WaveNet']
Training timeseries model WaveNet. Training for up to 599.9s of the 599.9s of remaining time.
Training timeseries model WaveNet. Training for up to 599.9s of the 599.9s of remaining time.
	Time limit adjusted due to model hyperparameters: 599.89s -> 539.90s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 599.89s -> 539.90s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused WaveNet to fail during training... Skipping this model.
	Warning: Exception caused WaveNet to fail during training... Skipping this model.
	name 'exit' is not defined
	name 'exit' is not defined
Training complete. Models trained: []
Training complete. Models trained: []
Total runtime: 107.82 s
Total runtime: 107.82 s
Trainer has no fit models that can predict.
Trainer has no fit models that can predict.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/CNN/modelo"
Beginning AutoGluon training... Time limit = 600s
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\CNN\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.11 GB / 7.88 GB (14.1%)
Disk Space Avail:   886.19 GB / 931.51 GB (95.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.11 GB / 7.88 GB (14.1%)
Disk Space Avail:   886.19 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 600,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'WaveNet': {}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 600,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	known_covariates:
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
	past_covariates:
		categorical:        ['Season']
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-04-26 17:30:26

Starting training. Start time is 2025-04-26 17:30:26
Models that will be trained: ['WaveNet']
Models that will be trained: ['WaveNet']
Training timeseries model WaveNet. Training for up to 599.9s of the 599.9s of remaining time.
Training timeseries model WaveNet. Training for up to 599.9s of the 599.9s of remaining time.
	Time limit adjusted due to model hyperparameters: 599.90s -> 539.91s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Time limit adjusted due to model hyperparameters: 599.90s -> 539.91s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	277.78  s     = Training runtime
	277.78  s     = Training runtime
Training complete. Models trained: ['WaveNet']
Training complete. Models trained: ['WaveNet']
Total runtime: 277.82 s
Total runtime: 277.82 s
Best model: WaveNet
Best model: WaveNet
Model not specified in predict, will default to the model with the best validation score: WaveNet
Model not specified in predict, will default to the model with the best validation score: WaveNet
Model not specified in predict, will default to the model with the best validation score: WaveNet
Model not specified in predict, will default to the model with the best validation score: WaveNet
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.24 GB / 15.93 GB (7.8%)
Disk Space Avail:   690.50 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:00:56
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM_lag/modelo"
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM_lag\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.17 GB / 15.93 GB (7.4%)
Disk Space Avail:   690.51 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:01:18
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	module 'sympy' has no attribute 'printing'
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 0.97 s
Trainer has no fit models that can predict.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM_lag/modelo"
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM_lag\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.72 GB / 15.93 GB (10.8%)
Disk Space Avail:   690.50 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:04:37
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	module 'sympy' has no attribute 'printing'
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 0.06 s
Trainer has no fit models that can predict.
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_lag\modelo
Model not specified in predict, will default to the model with the best validation score: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM_lag/modelo"
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM_lag\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.13 GB / 15.93 GB (13.4%)
Disk Space Avail:   690.50 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:31:17
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	module 'sympy' has no attribute 'printing'
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 0.05 s
Trainer has no fit models that can predict.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM_lag/modelo"
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM_lag\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.28 GB / 15.93 GB (14.3%)
Disk Space Avail:   690.50 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:32:42
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	module 'sympy' has no attribute 'printing'
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 0.06 s
Trainer has no fit models that can predict.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/LSTM_lag/modelo"
Beginning AutoGluon training... Time limit = 3600s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\LSTM_lag\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.20 GB / 15.93 GB (13.8%)
Disk Space Avail:   690.50 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'DeepAR': {'context_length': 168,
                                'dropout': 0.1,
                                'epochs': 20,
                                'hidden_size': 64,
                                'learning_rate': 0.001,
                                'num_layers': 2,
                                'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour',
                            'TimeOfDay',
                            'Temperature',
                            'DayOfTheWeek',
                            'lag_168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 3600,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature', 'lag_168']
	past_covariates:
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-23 09:36:08
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 3600.0s of the 3600.0s of remaining time.
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	module 'sympy' has no attribute 'printing'
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 0.05 s
Trainer has no fit models that can predict.
