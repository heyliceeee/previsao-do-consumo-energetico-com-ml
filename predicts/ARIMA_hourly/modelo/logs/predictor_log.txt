Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.63 GB / 15.93 GB (16.5%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-05-22 18:27:37
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 291.6s of the 291.6s of remaining time.
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.80 GB / 15.93 GB (11.3%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.80 GB / 15.93 GB (11.3%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-05-22 18:30:51

Starting training. Start time is 2025-05-22 18:30:51
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Frequency 'H' stored as 'h'
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.66 GB / 15.93 GB (10.4%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.66 GB / 15.93 GB (10.4%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.60 GB / 15.93 GB (10.0%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.60 GB / 15.93 GB (10.0%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Frequency 'H' stored as 'h'
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.48 GB / 15.93 GB (9.3%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.48 GB / 15.93 GB (9.3%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'ActiveEnergy(kWh)'
	target: 'ActiveEnergy(kWh)'
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-05-22 18:35:38

Starting training. Start time is 2025-05-22 18:35:38
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly_kWh/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly_kWh\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'ActiveEnergy(kWh)',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'ActiveEnergy(kWh)'
	target: 'ActiveEnergy(kWh)'
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-05-22 18:35:46

Starting training. Start time is 2025-05-22 18:35:46
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Frequency 'H' stored as 'h'
Frequency 'H' stored as 'h'
Frequency 'H' stored as 'h'
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.57 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.57 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.57 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.56 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.56 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.56 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.56 GB / 15.93 GB (9.8%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.47 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.47 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.47 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.47 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.47 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.66 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7656 rows, 1 time series. Median time series length is 7656 (min=7656, max=7656). 
Provided train_data has 7656 rows, 1 time series. Median time series length is 7656 (min=7656, max=7656). 
Provided train_data has 7656 rows, 1 time series. Median time series length is 7656 (min=7656, max=7656). 
Provided train_data has 7656 rows, 1 time series. Median time series length is 7656 (min=7656, max=7656). 
Provided train_data has 7656 rows, 1 time series. Median time series length is 7656 (min=7656, max=7656). 
Provided tuning_data has 7680 rows, 1 time series. Median time series length is 7680 (min=7680, max=7680). 
Provided tuning_data has 7680 rows, 1 time series. Median time series length is 7680 (min=7680, max=7680). 
Provided tuning_data has 7680 rows, 1 time series. Median time series length is 7680 (min=7680, max=7680). 
Provided tuning_data has 7680 rows, 1 time series. Median time series length is 7680 (min=7680, max=7680). 
Provided tuning_data has 7680 rows, 1 time series. Median time series length is 7680 (min=7680, max=7680). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 18:38:41

Starting training. Start time is 2025-05-22 18:38:41

Starting training. Start time is 2025-05-22 18:38:41

Starting training. Start time is 2025-05-22 18:38:41

Starting training. Start time is 2025-05-22 18:38:41
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.52 GB / 15.93 GB (9.6%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 19:02:19

Starting training. Start time is 2025-05-22 19:02:19

Starting training. Start time is 2025-05-22 19:02:19

Starting training. Start time is 2025-05-22 19:02:19

Starting training. Start time is 2025-05-22 19:02:19

Starting training. Start time is 2025-05-22 19:02:19
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.15 GB / 15.93 GB (7.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided train_data has 7967 rows, 1 time series. Median time series length is 7967 (min=7967, max=7967). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
Provided tuning_data has 7991 rows, 1 time series. Median time series length is 7991 (min=7991, max=7991). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24

Starting training. Start time is 2025-05-22 19:04:24
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.46 GB / 15.93 GB (9.2%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57

Starting training. Start time is 2025-05-22 19:08:57
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.07 GB / 15.93 GB (6.7%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29

Starting training. Start time is 2025-05-22 19:10:29
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA_hourly/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA_hourly\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.61 GB / 15.93 GB (10.1%)
Disk Space Avail:   690.65 GB / 931.46 GB (74.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (168, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided train_data has 7824 rows, 1 time series. Median time series length is 7824 (min=7824, max=7824). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
Provided tuning_data has 7848 rows, 1 time series. Median time series length is 7848 (min=7848, max=7848). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14

Starting training. Start time is 2025-05-22 19:16:14
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Total runtime: 0.02 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
