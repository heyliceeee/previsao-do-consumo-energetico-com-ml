Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_150311'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.05 GB / 15.93 GB (25.4%)
Disk Space Avail:   717.26 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'DeepAR': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:03:11
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.93s -> 269.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	name 'exit' is not defined
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 12.11 s
Trainer has no fit models that can predict.
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_150326"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_150326'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.91 GB / 15.93 GB (24.6%)
Disk Space Avail:   717.26 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'DeepAR': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:03:26
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.96s -> 269.96s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1005       = Validation score (-MASE)
	146.76  s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Total runtime: 146.87 s
Best model: DeepAR
Best model score: -0.1005
Model not specified in predict, will default to the model with the best validation score: DeepAR
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_150644"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_150644'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.85 GB / 15.93 GB (24.2%)
Disk Space Avail:   717.26 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'DeepAR': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:06:44
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.96s -> 269.96s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1005       = Validation score (-MASE)
	153.31  s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['DeepAR']
Total runtime: 153.43 s
Best model: DeepAR
Best model score: -0.1005
Model not specified in predict, will default to the model with the best validation score: DeepAR
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_154531"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_154531'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.70 GB / 15.93 GB (10.7%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'DeepAR': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:45:31
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.95s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	name 'exit' is not defined
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 21.83 s
Trainer has no fit models that can predict.
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_154555"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_154555'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       1.58 GB / 15.93 GB (9.9%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:45:55
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4018       = Validation score (-MASE)
	0.02    s     = Training runtime
	10.51   s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 10.54 s
Best model: ARIMA
Best model score: -2.4018
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_155200"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_155200'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.69 GB / 15.93 GB (16.9%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'DeepAR': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:52:00
Models that will be trained: ['DeepAR']
Training timeseries model DeepAR. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.93s -> 269.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused DeepAR to fail during training... Skipping this model.
	name 'exit' is not defined
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 95.59 s
Trainer has no fit models that can predict.
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_155342"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_155342'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.60 GB / 15.93 GB (16.3%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'PatchTST': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7968 rows, 1 time series. Median time series length is 7968 (min=7968, max=7968). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 16:53:42
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA']
Training timeseries model TemporalFusionTransformer. Training for up to 60.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 59.99s -> 53.99s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.2171       = Validation score (-MASE)
	54.37   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 61.4s of the 245.6s of remaining time.
	Time limit adjusted due to model hyperparameters: 61.37s -> 55.23s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.2000       = Validation score (-MASE)
	55.43   s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 63.3s of the 190.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 63.31s -> 56.98s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1522       = Validation score (-MASE)
	56.01   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 67.0s of the 133.9s of remaining time.
	-2.4018       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.52    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'ARIMA': 0.03, 'DeepAR': 0.55, 'PatchTST': 0.42}
	-0.1307       = Validation score (-MASE)
	0.13    s     = Training runtime
	2.66    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA', 'WeightedEnsemble']
Total runtime: 168.75 s
Best model: WeightedEnsemble
Best model score: -0.1307
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_160010"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_160010'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.17 GB / 15.93 GB (26.2%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'PatchTST': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:00:10
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA']
Training timeseries model TemporalFusionTransformer. Training for up to 60.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 59.98s -> 53.98s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1287       = Validation score (-MASE)
	54.36   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 61.4s of the 245.6s of remaining time.
	Time limit adjusted due to model hyperparameters: 61.37s -> 55.23s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.2105       = Validation score (-MASE)
	55.60   s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 63.3s of the 189.8s of remaining time.
	Time limit adjusted due to model hyperparameters: 63.25s -> 56.93s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0900       = Validation score (-MASE)
	41.21   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 74.3s of the 148.6s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.47    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 0.15, 'PatchTST': 0.79, 'TemporalFusionTransformer': 0.06}
	-0.0769       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.19    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA', 'WeightedEnsemble']
Total runtime: 154.08 s
Best model: WeightedEnsemble
Best model score: -0.0769
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_160455"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_160455'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.52 GB / 15.93 GB (28.4%)
Disk Space Avail:   717.25 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'PatchTST': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:04:55
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA']
Training timeseries model TemporalFusionTransformer. Training for up to 60.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 59.98s -> 53.98s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1297       = Validation score (-MASE)
	54.38   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 61.4s of the 245.5s of remaining time.
	Time limit adjusted due to model hyperparameters: 61.36s -> 55.23s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.2013       = Validation score (-MASE)
	55.49   s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 63.3s of the 189.9s of remaining time.
	Time limit adjusted due to model hyperparameters: 63.29s -> 56.96s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0900       = Validation score (-MASE)
	36.96   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 76.5s of the 152.9s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.12    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 0.17, 'PatchTST': 0.77, 'TemporalFusionTransformer': 0.06}
	-0.0763       = Validation score (-MASE)
	0.13    s     = Training runtime
	0.17    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA', 'WeightedEnsemble']
Total runtime: 149.35 s
Best model: WeightedEnsemble
Best model score: -0.0763
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_160915"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_160915'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.70 GB / 15.93 GB (29.5%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:09:15
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR', 'ARIMA']
Training timeseries model TemporalFusionTransformer. Training for up to 75.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 74.98s -> 67.48s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0972       = Validation score (-MASE)
	67.74   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 77.4s of the 232.2s of remaining time.
	Time limit adjusted due to model hyperparameters: 77.37s -> 69.64s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1030       = Validation score (-MASE)
	69.85   s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 81.1s of the 162.2s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'ARIMA': 0.01, 'DeepAR': 0.46, 'TemporalFusionTransformer': 0.53}
	-0.0811       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.24    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'ARIMA', 'WeightedEnsemble']
Total runtime: 138.06 s
Best model: WeightedEnsemble
Best model score: -0.0811
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_161549"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_161549'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.98 GB / 15.93 GB (31.2%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:15:49
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163247"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163438"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163438'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.20 GB / 15.93 GB (26.3%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:34:38
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.54    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.57 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-001"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-002"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-003"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-004"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-005"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-006"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-007"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-008"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-009"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163442-010"
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163822"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163822'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.76 GB / 15.93 GB (23.6%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:22
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.18 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163825"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163825'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.49 GB / 15.93 GB (21.9%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Temperature']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.20    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.23 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163829"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163829'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Hour']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:29
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163829-001"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163829-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.26 GB / 15.93 GB (20.4%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:29
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163829-002"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163829-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.25 GB / 15.93 GB (20.4%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['Season']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:29
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163829-003"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163829-003'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['IsHoliday']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163830"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163830'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Manhã']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163830-001"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163830-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Noite']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.18 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163830-002"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163830-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.28 GB / 15.93 GB (20.6%)
Disk Space Avail:   717.24 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163830-003"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163830-003'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag1']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163831"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163831'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag24']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:31
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_163831-001"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_163831-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.28 GB / 15.93 GB (20.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag168']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:38:31
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164049"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164049'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.34 GB / 15.93 GB (21.0%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'ETS': {},
                     'MLP': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:40:49
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164229"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164229'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.37 GB / 15.93 GB (21.1%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'ETS': {},
                     'PatchTST': {},
                     'TemporalFusionTransformer': {},
                     'Theta': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:42:29
Models that will be trained: ['ETS', 'Theta', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA']
Training timeseries model ETS. Training for up to 42.9s of the 300.0s of remaining time.
	-2.1723       = Validation score (-MASE)
	0.02    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 49.8s of the 298.9s of remaining time.
	-1.1490       = Validation score (-MASE)
	0.02    s     = Training runtime
	17.25   s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 56.3s of the 281.6s of remaining time.
	Time limit adjusted due to model hyperparameters: 56.30s -> 50.67s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1275       = Validation score (-MASE)
	50.97   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 57.6s of the 230.6s of remaining time.
	Time limit adjusted due to model hyperparameters: 57.61s -> 51.85s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1476       = Validation score (-MASE)
	52.38   s     = Training runtime
	0.11    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 59.4s of the 178.1s of remaining time.
	Time limit adjusted due to model hyperparameters: 59.33s -> 53.39s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0827       = Validation score (-MASE)
	53.60   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 62.2s of the 124.4s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 0.36, 'PatchTST': 0.6, 'Theta': 0.03}
	-0.0736       = Validation score (-MASE)
	0.26    s     = Training runtime
	17.39   s     = Validation (prediction) runtime
Training complete. Models trained: ['ETS', 'Theta', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA', 'WeightedEnsemble']
Total runtime: 175.93 s
Best model: WeightedEnsemble
Best model score: -0.0736
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164525"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164525'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.60 GB / 15.93 GB (22.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Temperature']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.08 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164526"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164526'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.48 GB / 15.93 GB (21.8%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Hour']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:26
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.13 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164530"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164530'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.25 GB / 15.93 GB (20.4%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:30
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.10 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164532"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164532'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['Season']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:32
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164532-001"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164532-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['IsHoliday']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164533"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164533'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Manhã']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164533-001"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164533-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.23 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Noite']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164533-002"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164533-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164533-003"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164533-003'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.11 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag1']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164533-004"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164533-004'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.11 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag24']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:34
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.20 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164534"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164534'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.12 GB / 15.93 GB (19.6%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag168']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:45:34
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_164914"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_164914'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.13 GB / 15.93 GB (19.7%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {},
                     'DeepAR': {},
                     'ETS': {},
                     'PatchTST': {},
                     'TemporalFusionTransformer': {},
                     'Theta': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:49:14
Models that will be trained: ['ETS', 'Theta', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA']
Training timeseries model ETS. Training for up to 42.9s of the 300.0s of remaining time.
	-2.1723       = Validation score (-MASE)
	0.02    s     = Training runtime
	1.14    s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 49.8s of the 298.8s of remaining time.
	-1.1490       = Validation score (-MASE)
	0.02    s     = Training runtime
	15.70   s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 56.6s of the 283.1s of remaining time.
	Time limit adjusted due to model hyperparameters: 56.60s -> 50.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1275       = Validation score (-MASE)
	51.29   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 57.9s of the 231.7s of remaining time.
	Time limit adjusted due to model hyperparameters: 57.90s -> 52.11s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1559       = Validation score (-MASE)
	52.36   s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training timeseries model PatchTST. Training for up to 59.7s of the 179.2s of remaining time.
	Time limit adjusted due to model hyperparameters: 59.71s -> 53.74s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0827       = Validation score (-MASE)
	53.93   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training timeseries model ARIMA. Training for up to 62.6s of the 125.2s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 0.29, 'PatchTST': 0.68, 'Theta': 0.03}
	-0.0733       = Validation score (-MASE)
	0.26    s     = Training runtime
	15.86   s     = Validation (prediction) runtime
Training complete. Models trained: ['ETS', 'Theta', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'ARIMA', 'WeightedEnsemble']
Total runtime: 175.12 s
Best model: WeightedEnsemble
Best model score: -0.0733
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165209"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165209'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.67 GB / 15.93 GB (23.0%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Temperature']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:52:09
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.93s -> 269.93s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0773       = Validation score (-MASE)
	59.08   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 59.13 s
Best model: PatchTST
Best model score: -0.0773
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165309"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165309'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.67 GB / 15.93 GB (23.0%)
Disk Space Avail:   717.22 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['Hour']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:53:09
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.95s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0568       = Validation score (-MASE)
	89.90   s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 89.95 s
Best model: PatchTST
Best model score: -0.0568
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165439"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165439'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.87 GB / 15.93 GB (24.3%)
Disk Space Avail:   717.21 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:54:39
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.93s -> 269.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0601       = Validation score (-MASE)
	64.75   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 64.81 s
Best model: PatchTST
Best model score: -0.0601
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165544"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165544'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.88 GB / 15.93 GB (24.4%)
Disk Space Avail:   717.21 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        ['Season']
		continuous (float): []

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:55:44
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0517       = Validation score (-MASE)
	74.92   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 74.97 s
Best model: PatchTST
Best model score: -0.0517
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165659"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165659'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.90 GB / 15.93 GB (24.5%)
Disk Space Avail:   717.21 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['IsHoliday']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:56:59
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.93s -> 269.94s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0440       = Validation score (-MASE)
	99.36   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 99.41 s
Best model: PatchTST
Best model score: -0.0440
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_165839"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_165839'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.50 GB / 15.93 GB (28.3%)
Disk Space Avail:   717.21 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Noite', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Manhã']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 17:58:39
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0519       = Validation score (-MASE)
	99.39   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 99.44 s
Best model: PatchTST
Best model score: -0.0519
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_170018"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_170018'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.63 GB / 15.93 GB (29.1%)
Disk Space Avail:   717.21 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Tarde', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Noite']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:00:18
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0580       = Validation score (-MASE)
	92.59   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 92.65 s
Best model: PatchTST
Best model score: -0.0580
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_170151"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_170151'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.64 GB / 15.93 GB (29.2%)
Disk Space Avail:   717.20 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'lag1', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['tod_Tarde']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:01:51
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0579       = Validation score (-MASE)
	76.60   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 76.66 s
Best model: PatchTST
Best model score: -0.0579
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_170308"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_170308'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.65 GB / 15.93 GB (29.2%)
Disk Space Avail:   717.20 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag1']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:03:08
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.1160       = Validation score (-MASE)
	83.84   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 83.89 s
Best model: PatchTST
Best model score: -0.1160
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_170432"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_170432'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       5.31 GB / 15.93 GB (33.3%)
Disk Space Avail:   717.20 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag24']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:04:32
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.94s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	-0.0606       = Validation score (-MASE)
	67.39   s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['PatchTST']
Total runtime: 67.44 s
Best model: PatchTST
Best model score: -0.0606
Model not specified in predict, will default to the model with the best validation score: PatchTST
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_170540"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_170540'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       5.30 GB / 15.93 GB (33.3%)
Disk Space Avail:   717.20 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'PatchTST': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]
	past_covariates:
		categorical:        []
		continuous (float): ['lag168']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:05:40
Models that will be trained: ['PatchTST']
Training timeseries model PatchTST. Training for up to 300.0s of the 300.0s of remaining time.
	Time limit adjusted due to model hyperparameters: 299.95s -> 269.95s (ag.max_time_limit=None, ag.max_time_limit_ratio=0.9, ag.min_time_limit=0)
	Warning: Exception caused PatchTST to fail during training... Skipping this model.
	name 'exit' is not defined
Not fitting ensemble as no models were successfully trained.
Training complete. Models trained: []
Total runtime: 49.48 s
Trainer has no fit models that can predict.
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_171142"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_171142'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.88 GB / 15.93 GB (24.3%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:11:42
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.53    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.58 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_171211"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_171211'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.63 GB / 15.93 GB (22.8%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 7800 rows, 1 time series. Median time series length is 7800 (min=7800, max=7800). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:12:11
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-2.4245       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.16    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.20 s
Best model: ARIMA
Best model score: -2.4245
Model not specified in predict, will default to the model with the best validation score: ARIMA
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_172416"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_172416'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.84 GB / 15.93 GB (24.1%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:24:16
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.57    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.60 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_172534"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_172534'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.46 GB / 15.93 GB (21.7%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:25:34
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.13    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.17 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_172731"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_172731'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.27 GB / 15.93 GB (20.5%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:27:31
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.17    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.20 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_172910"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_172910'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.08 GB / 15.93 GB (19.3%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:29:10
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.24    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.28 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_173101"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_173101'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.84 GB / 15.93 GB (24.1%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:31:01
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.10 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_173710"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_173710'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.81 GB / 15.93 GB (23.9%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:37:10
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.50    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.53 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_173728"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_173728'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.43 GB / 15.93 GB (21.6%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:37:28
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.62    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.66 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_173805"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_173805'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.30 GB / 15.93 GB (20.7%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:38:05
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.25    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.28 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_173905"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_173905'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.18 GB / 15.93 GB (19.9%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:39:05
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.21    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.26 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_174025"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_174025'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.05 GB / 15.93 GB (19.1%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:40:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.13 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_174342"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_174342'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.36 GB / 15.93 GB (21.1%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:43:43
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_174921"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_174921'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.73 GB / 15.93 GB (23.4%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:49:21
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.64    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.67 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_175126"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_175126'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.38 GB / 15.93 GB (21.2%)
Disk Space Avail:   717.19 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:51:26
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.48    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.52 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_175354"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_175354'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.18 GB / 15.93 GB (20.0%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:53:54
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.32    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.35 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_175525"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_175525'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.36 GB / 15.93 GB (21.1%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 18:55:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.08    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_180133"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_180133'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.68 GB / 15.93 GB (23.1%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:01:33
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.56    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.59 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_180405"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_180405'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.39 GB / 15.93 GB (21.3%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:04:05
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.18    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.21 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_180650"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_180650'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.62 GB / 15.93 GB (22.8%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:06:50
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_181338"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_181338'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.64 GB / 15.93 GB (22.9%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:13:38
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.49    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.52 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_181621"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_181621'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.42 GB / 15.93 GB (21.4%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:16:21
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.14    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.17 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_181716"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_181716'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.28 GB / 15.93 GB (20.6%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:17:17
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.21    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.24 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_181845"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_181845'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.40 GB / 15.93 GB (21.3%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 19:18:46
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.10 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_192802"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_192802'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       5.07 GB / 15.93 GB (31.9%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:28:02
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.86    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.89 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_193045"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_193045'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.39 GB / 15.93 GB (27.6%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:30:45
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.18 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_193218"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_193218'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.19 GB / 15.93 GB (26.3%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:32:19
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.12    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.16 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_193424"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_193424'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.28 GB / 15.93 GB (26.9%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:34:24
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.11 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_193656"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_193656'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.99 GB / 15.93 GB (25.0%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:36:56
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_193926"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_193926'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.47 GB / 15.93 GB (21.8%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:39:26
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.13 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_194310"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_194310'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.30 GB / 15.93 GB (20.7%)
Disk Space Avail:   717.18 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:43:10
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195129"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195129'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.41 GB / 15.93 GB (21.4%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:51:29
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.53    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.56 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195200"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195200'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.04 GB / 15.93 GB (19.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:52:00
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.26    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.29 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195403"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195403'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.93 GB / 15.93 GB (18.4%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:54:03
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.20    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.23 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195540"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195540'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.04 GB / 15.93 GB (19.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:55:40
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.8s of the 299.8s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.11    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.28 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195740"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195740'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.51 GB / 15.93 GB (22.0%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:57:40
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_195744"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_195744'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.84 GB / 15.93 GB (24.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 20:57:44
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.47    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.50 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_200154"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_200154'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.67 GB / 15.93 GB (23.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:01:54
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.11    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.14 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_200422"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_200422'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.80 GB / 15.93 GB (23.8%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:04:22
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.15 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_200431"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_200431'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.65 GB / 15.93 GB (22.9%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:04:32
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_200654"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_200654'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.73 GB / 15.93 GB (23.4%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:06:54
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.56    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.60 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_201129"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_201129'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.84 GB / 15.93 GB (24.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:11:29
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.12    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.18 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_201441"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_201441'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.69 GB / 15.93 GB (23.2%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:14:41
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_201714"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_201714'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.68 GB / 15.93 GB (23.1%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:17:14
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.13 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_201825"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_201825'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.55 GB / 15.93 GB (22.3%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:18:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_202206"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_202206'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.53 GB / 15.93 GB (22.2%)
Disk Space Avail:   717.17 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:22:06
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.12 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_202607"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_202607'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.71 GB / 15.93 GB (23.3%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:26:07
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.13 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_202721"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_202721'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.58 GB / 15.93 GB (22.5%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:27:21
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_202807"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_202807'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.55 GB / 15.93 GB (22.3%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:28:07
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.34    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.37 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_203116"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_203116'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.51 GB / 15.93 GB (22.0%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:31:16
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.11 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_203359"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_203359'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.60 GB / 15.93 GB (22.6%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:33:59
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.08 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_203634"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_203634'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.72 GB / 15.93 GB (23.4%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:36:34
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.15 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_203951"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_203951'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.10 GB / 15.93 GB (25.7%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:39:51
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.08 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_204008"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_204008'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.02 GB / 15.93 GB (25.2%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:40:08
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.62    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.66 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_204131"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_204131'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.92 GB / 15.93 GB (24.6%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:41:31
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.18 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_204225"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_204225'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.72 GB / 15.93 GB (23.3%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:42:25
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.07 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_204239"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_204239'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.65 GB / 15.93 GB (22.9%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:42:39
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.13    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.17 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_205554"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_205554'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.02 GB / 15.93 GB (25.3%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:55:54
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.81    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.85 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_205734"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_205734'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.17 GB / 15.93 GB (26.2%)
Disk Space Avail:   717.16 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:57:35
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.28    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.32 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_205916"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_205916'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.91 GB / 15.93 GB (24.5%)
Disk Space Avail:   717.15 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 21:59:16
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.5798       = Validation score (-MASE)
	0.01    s     = Training runtime
	2.27    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 2.31 s
Best model: ARIMA
Best model score: -1.5798
No path specified. Models will be saved in: "AutogluonModels\ag-20250419_210247"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\AutogluonModels\ag-20250419_210247'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       4.22 GB / 15.93 GB (26.5%)
Disk Space Avail:   717.15 GB / 931.46 GB (77.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': {'ARIMA': {}},
 'known_covariates_names': ['Temperature',
                            'Hour',
                            'DayOfTheWeek',
                            'Season',
                            'IsHoliday',
                            'tod_Manhã',
                            'tod_Noite',
                            'tod_Tarde',
                            'lag1',
                            'lag24',
                            'lag168'],
 'num_val_windows': 1,
 'prediction_length': 23,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Inferred time series frequency: 'h'
Provided train_data has 5493 rows, 1 time series. Median time series length is 5493 (min=5493, max=5493). 

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['DayOfTheWeek', 'Season']
		continuous (float): ['Temperature', 'Hour', 'IsHoliday', 'tod_Manhã', 'tod_Noite', 'tod_Tarde', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-19 22:02:47
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	-1.3000       = Validation score (-MASE)
	0.01    s     = Training runtime
	0.08    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Best model score: -1.3000
