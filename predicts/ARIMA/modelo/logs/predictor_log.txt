Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       3.91 GB / 15.93 GB (24.6%)
Disk Space Avail:   719.78 GB / 931.46 GB (77.3%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-21 12:31:40
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 300.0s of the 300.0s of remaining time.
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Total runtime: 0.02 s
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          12
GPU Count:          0
Memory Avail:       2.09 GB / 15.93 GB (13.1%)
Disk Space Avail:   701.42 GB / 931.46 GB (75.3%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-23 12:52:26
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	0.01    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Total runtime: 0.04 s
Best model: ARIMA
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\XARIMA\modelo
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\XARIMA\modelo
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.91 GB / 7.88 GB (11.6%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-26 16:43:46
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 292.7s of the 292.7s of remaining time.
	0.02    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Total runtime: 0.12 s
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/XARIMA/modelo"
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\XARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.96 GB / 7.88 GB (12.2%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'covariate_regressor': 'CAT',
                                    'target_scaler': 'standard'}},
 'known_covariates_names': ['Hour', 'TimeOfDay', 'Temperature', 'DayOfTheWeek'],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	known_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek']
		continuous (float): ['Hour', 'Temperature']
	past_covariates:
		categorical:        ['Season']
		continuous (float): ['ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', 'IsHoliday', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-04-26 16:45:15
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.8s of the 299.8s of remaining time.
	-0.0852       = Validation score (-WQL)
	33.94   s     = Training runtime
	8.35    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['ARIMA']
Total runtime: 42.52 s
Best model: ARIMA
Best model score: -0.0852
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/linearRegression/modelo"
Preset alias specified: 'medium' maps to 'medium_quality'.
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
Memory Avail:       0.83 GB / 7.88 GB (10.5%)
Disk Space Avail:   886.20 GB / 931.51 GB (95.1%)
===================================================
Presets specified: ['medium']
Beginning AutoGluon training ... Time limit = 300s
AutoGluon will save models to "D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\linearRegression\modelo"
Train Data Rows:    7992
Train Data Columns: 4
Tuning Data Rows:    24
Tuning Data Columns: 4
Label Column:       EnergyNormalized
AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).
	Label info (max, min, mean, stddev): (0.1517218738549846, 0.005890280091559903, 0.06812, 0.02939)
	If 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])
Problem Type:       regression
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    817.20 MB
	Train Data (Original)  Memory Usage: 0.99 MB (0.1% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Stage 5 Generators:
		Fitting DropDuplicatesFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		('float', [])  : 1 | ['Temperature']
		('int', [])    : 1 | ['Hour']
		('object', []) : 2 | ['TimeOfDay', 'DayOfTheWeek']
	Types of features in processed data (raw dtype, special dtypes):
		('category', []) : 2 | ['TimeOfDay', 'DayOfTheWeek']
		('float', [])    : 1 | ['Temperature']
		('int', [])      : 1 | ['Hour']
	0.2s = Fit runtime
	4 features in original data used to generate 4 features in processed data.
	Train Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.3s ...
AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
User-specified model hyperparameters to be fit:
{
	'LR': [{}],
}
Fitting 1 L1 models, fit_strategy="sequential" ...
Fitting model: LinearModel ... Training model for up to 299.70s of the 299.69s of remaining time.
	-0.0124	 = Validation score   (-mean_absolute_error)
	0.21s	 = Training   runtime
	0.02s	 = Validation runtime
Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.70s of the 299.40s of remaining time.
	Ensemble Weights: {'LinearModel': 1.0}
	-0.0124	 = Validation score   (-mean_absolute_error)
	0.02s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 0.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1411.7 rows/s (24 batch size)
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\linearRegression\modelo")
TabularPredictor saved. To load, use: predictor = TabularPredictor.load("D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\linearRegression\modelo")
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Warning: path already exists! This predictor may overwrite an existing predictor! path="predicts/ARIMA/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.16 GB / 7.88 GB (14.8%)
Disk Space Avail:   886.17 GB / 931.51 GB (95.1%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.16 GB / 7.88 GB (14.8%)
Disk Space Avail:   886.17 GB / 931.51 GB (95.1%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	past_covariates:
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-05-02 13:14:49

Starting training. Start time is 2025-05-02 13:14:49
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 288.3s of the 288.3s of remaining time.
Training timeseries model ARIMA. Training for up to 288.3s of the 288.3s of remaining time.
	0.02    s     = Training runtime
	0.02    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.20 s
Total runtime: 0.20 s
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       1.19 GB / 7.88 GB (15.1%)
Disk Space Avail:   879.67 GB / 931.51 GB (94.4%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:
	target: 'EnergyNormalized'
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
		categorical:        []
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-07-08 13:23:55
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 273.4s of the 273.4s of remaining time.
	0.03    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Total runtime: 0.46 s
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.83 GB / 7.88 GB (10.5%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.83 GB / 7.88 GB (10.5%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	past_covariates:
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-07-08 16:43:32

Starting training. Start time is 2025-07-08 16:43:32
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 296.9s of the 296.9s of remaining time.
Training timeseries model ARIMA. Training for up to 296.9s of the 296.9s of remaining time.
	0.64    s     = Training runtime
	0.64    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 3.64 s
Total runtime: 3.64 s
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.90 GB / 7.88 GB (11.4%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.90 GB / 7.88 GB (11.4%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       0.90 GB / 7.88 GB (11.4%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	past_covariates:
	past_covariates:
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================

Starting training. Start time is 2025-07-08 16:49:35

Starting training. Start time is 2025-07-08 16:49:35

Starting training. Start time is 2025-07-08 16:49:35
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	0.04    s     = Training runtime
	0.04    s     = Training runtime
	0.04    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.06 s
Total runtime: 0.06 s
Total runtime: 0.06 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Loading predictor from path D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Warning: path already exists! This predictor may overwrite an existing predictor! path="../predicts/ARIMA/modelo"
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
Beginning AutoGluon training... Time limit = 300s
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
AutoGluon will save models to 'D:\githubProjects\previsao-do-consumo-energetico-com-ml\predicts\ARIMA\modelo'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       2.28 GB / 7.88 GB (28.9%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       2.28 GB / 7.88 GB (28.9%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       2.28 GB / 7.88 GB (28.9%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.12.10
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.26100
CPU Count:          8
GPU Count:          0
Memory Avail:       2.28 GB / 7.88 GB (28.9%)
Disk Space Avail:   872.27 GB / 931.51 GB (93.6%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': WQL,
 'freq': 'h',
 'hyperparameters': {'ARIMAModel': {'order': (1, 1, 1),
                                    'seasonal_order': (1, 0, 1, 24),
                                    'target_scaler': 'standard'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 24,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': True,
 'target': 'EnergyNormalized',
 'time_limit': 300,
 'verbosity': 2}

Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided train_data has 7992 rows, 1 time series. Median time series length is 7992 (min=7992, max=7992). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
Provided tuning_data has 8016 rows, 1 time series. Median time series length is 8016 (min=8016, max=8016). 
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.
	Setting num_val_windows = 0 (disabling backtesting on train_data) because tuning_data is provided.

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	target: 'EnergyNormalized'
	past_covariates:
	past_covariates:
	past_covariates:
	past_covariates:
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		categorical:        ['TimeOfDay', 'DayOfTheWeek', 'Season']
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
		continuous (float): ['Hour', 'ActiveEnergy(kWh)', 'Day', 'Month', 'Year', 'IsWeekend', ...]
	static_features:
	static_features:
	static_features:
	static_features:
		categorical:        []
		categorical:        []
		categorical:        []
		categorical:        []
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']
		continuous (float): ['PopulationDensity']

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:

AutoGluon will ignore following non-numeric/non-informative columns:
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']
	ignored covariates:      ['Date']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'

AutoGluon will gauge predictive performance using evaluation metric: 'WQL'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2025-07-08 16:56:27

Starting training. Start time is 2025-07-08 16:56:27

Starting training. Start time is 2025-07-08 16:56:27

Starting training. Start time is 2025-07-08 16:56:27
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Models that will be trained: ['ARIMA']
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
Training timeseries model ARIMA. Training for up to 299.9s of the 299.9s of remaining time.
	0.02    s     = Training runtime
	0.02    s     = Training runtime
	0.02    s     = Training runtime
	0.02    s     = Training runtime
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Training complete. Models trained: ['ARIMA']
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Total runtime: 0.03 s
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Best model: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
	Warning: ARIMA failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
Model not specified in predict, will default to the model with the best validation score: ARIMA
